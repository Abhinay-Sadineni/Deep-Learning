{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment 3 AI5100\n",
        "Name : SADINENI ABHINAY\n",
        "\n",
        "Roll NO: CS21BTECH11055"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "th_i_G7vvy86"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "#importing these libaraies (for dataset download only) didn't use anywhere else\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju1TmxjHvy88",
        "outputId": "c446ea9e-2cac-4cf0-baae-b6d7c7672bcb"
      },
      "outputs": [],
      "source": [
        "if(torch.cuda.is_available()): torch.cuda.empty_cache()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataSet Download "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "50000\n"
          ]
        }
      ],
      "source": [
        "#Used  PY torch tutorials(official) Normalization values \n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))  \n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# Load CIFAR-10 test dataset\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "print(len(train_loader.dataset))  # Number of batches in training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model , test_loader):\n",
        "    # Evaluate the model on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs.data, dim=1)  \n",
        "            total += labels.size(0)\n",
        "            print(labels.size())\n",
        "            correct += (predicted.squeeze() == labels).sum().item()  \n",
        "    accuracy = (correct / total) * 100\n",
        "    print('Accuracy on the test dataset: %.2f %%' % accuracy)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([16, 3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "for data in test_loader:\n",
        "    print(data[0].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ8wTG3lvy88"
      },
      "source": [
        "## 1. Object Recognition using CNN and self attention layers\n",
        "Consider Image , and pass it thorught Convolution layer we will get CxHxW activation map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inside a Self attention layer:\n",
        "* Here each we are giving an input of HxW elements with each element of C dimension\n",
        "* Then do a 1x1 convolution with three different set of W<sub>q</sub> W<sub>k</sub> W<sub>v</sub> to get queries , keys , values\n",
        "* Let Q , K , V be query , key , value vectors with dimensions C'xHxW\n",
        "* now calculate self attention vector : softmax(QK^T)V\n",
        "* now do 1x1 convolution and convert this attention to CxHxW and add to original activation map and return the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KAa6-4mvvy8-"
      },
      "outputs": [],
      "source": [
        "#self attention layer\n",
        "class SelfAttentionLayer_CNN(nn.Module):\n",
        "\n",
        "        def __init__(self, C , D_Q , D_V ):\n",
        "            super(SelfAttentionLayer_CNN, self).__init__()\n",
        "            self.C = C\n",
        "            self.D_Q = D_Q\n",
        "            self.D_V = D_V\n",
        "            self.conv_Q = nn.Conv2d(C, D_Q , kernel_size=1, stride=1, padding=0)\n",
        "            self.conv_K = nn.Conv2d(C, D_Q , kernel_size=1 , stride=1 , padding=0)\n",
        "            self.conv_V = nn.Conv2d(C, D_V , kernel_size=1 ,stride=1 ,padding=0)\n",
        "            self.conv_S = nn.Conv2d(D_V , C , kernel_size=1 ,stride=1 ,padding=0)\n",
        "\n",
        "        def forward(self , X):\n",
        "             size = X.size()\n",
        "             \n",
        "             #get query , key , value\n",
        "             Q = self.conv_Q(X)\n",
        "             K = self.conv_K(X)\n",
        "             V = self.conv_V(X)\n",
        " \n",
        "             Q = Q.view(size[0] , self.D_Q, size[2]*size[3])  # batch x D_q x (HW)\n",
        "             K = K.view(size[0], self.D_Q , size[2]*size[3])  # batch x D_q x (HW)\n",
        "             V = V.view(size[0] , self.D_V ,size[2]*size[3])  # batch x D_v x (HW)\n",
        "\n",
        "            # Calculate dot product for attention\n",
        "             dot_products =  torch.bmm(K.transpose(1,2), Q)/ torch.sqrt(torch.tensor(self.D_Q, dtype=torch.float32))  # batch x [ ( D_q x HW)T (D_q x HW )]\n",
        "\n",
        "             softmax = torch.nn.functional.softmax(dot_products, dim=2) # batch x HWxHW\n",
        "            \n",
        "            #Multiple with value\n",
        "             self_attention =  torch.bmm(V, softmax)  # batch x[ (D_v x HW)(D_V xHW)]\n",
        "\n",
        "             self_attention =  self_attention.view(size[0] ,self.D_V , size[2] ,size[3] ) # batch x D_v x H x W\n",
        "            \n",
        "             #again do convolution to get attention to input value\n",
        "             # Add residual connection \n",
        "             add_residual = self.conv_S(self_attention) + X #   batch x C x H x W\n",
        "\n",
        "             return  add_residual\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN_SA Network archiecture\n",
        " CONV - > MAXPOOL -> 4x [ CONV -> SelfAttention] -> CONV -> GAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hCbfpaHYvy8_"
      },
      "outputs": [],
      "source": [
        "#Object reconginition with CNN and SA\n",
        "\n",
        "class Object_reconginition_CNN_SA(nn.Module):\n",
        "    def __init__(self, C_in, C_in_SA, D_Q, D_V, N_C):\n",
        "        super(Object_reconginition_CNN_SA, self).__init__()\n",
        "\n",
        "        #First Convolution Layer\n",
        "        self.conv0 = nn.Conv2d(C_in, C_in_SA, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu0 = nn.ReLU()\n",
        "\n",
        "        #Max Pool Layer\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #Four blocks of Convolution followed by Self Attention Layer\n",
        "        self.module_list = nn.Sequential(*[nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(C_in_SA, C_in_SA, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            SelfAttentionLayer_CNN(C_in_SA, D_Q, D_V)\n",
        "        ) for i in range(4)])\n",
        "\n",
        "        #Last Convolution Layer\n",
        "        self.conv_last = nn.Conv2d(C_in_SA, N_C, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu_last = nn.ReLU()\n",
        "\n",
        "        #GAP\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    #Forward Function that feeds the input to the network\n",
        "    def forward(self, X):\n",
        "        X = self.conv0(X)\n",
        "        X = self.relu0(X)\n",
        "        X = self.maxpool(X)\n",
        "        for module in self.module_list:\n",
        "            X = module(X)\n",
        "        X = self.conv_last(X)\n",
        "        X = self.relu_last(X)\n",
        "        X = self.global_avg_pool(X)\n",
        "        return X\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    def train_model(self, train_loader, learning_rate, epochs, batch_size,  device):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        print(\"Training CNN-SA Network:\")\n",
        "\n",
        "        Train_loss_data = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "                #Save inputs in device\n",
        "                inputs, labels = data[0].to(device), data[1].to(device) \n",
        "\n",
        "                #Clear the gradient\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(inputs)  \n",
        "                loss = criterion(outputs.squeeze(), labels)  \n",
        "\n",
        "                #Go backward\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                running_loss += loss.item()\n",
        "\n",
        "            print('epoch : %d ------> loss: %.3f' %\n",
        "                  (epoch + 1, running_loss / len(train_loader)))\n",
        "            Train_loss_data.append(running_loss / len(train_loader))\n",
        "\n",
        "        return Train_loss_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5zxgbqxvy8_",
        "outputId": "7f0b77fc-c3a2-4013-ecb9-a33bc73e058b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training CNN-SA Network:\n",
            "epoch : 1 ------> loss: 2.214\n",
            "epoch : 2 ------> loss: 1.909\n",
            "epoch : 3 ------> loss: 1.348\n",
            "epoch : 4 ------> loss: 1.160\n",
            "epoch : 5 ------> loss: 1.049\n",
            "epoch : 6 ------> loss: 0.974\n",
            "epoch : 7 ------> loss: 0.922\n",
            "epoch : 8 ------> loss: 0.878\n",
            "epoch : 9 ------> loss: 0.842\n",
            "epoch : 10 ------> loss: 0.807\n"
          ]
        }
      ],
      "source": [
        "# Training constraints\n",
        "epochs = 10\n",
        "lr = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize your model\n",
        "model = Object_reconginition_CNN_SA(C_in=3, C_in_SA=32, D_Q=16, D_V=16, N_C=10).to(device)\n",
        "\n",
        "#Train the model\n",
        "Train_loss_data1 = model.train_model(train_loader, lr, epochs, 128 , device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDioJsB9Ey0a",
        "outputId": "d20c05e9-0c03-4e49-afdd-cdee3b2ea041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([16])\n",
            "Accuracy on the test dataset: 69.29 %\n"
          ]
        }
      ],
      "source": [
        "AC1 = evaluate(model,test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Object Recognition with Vision Transformer\n",
        "This model is based on encoder only transformer \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Multi Headed Attention Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MHA_layer(nn.Module):\n",
        "    def __init__(self, input_dim , N_heads , D_Q , D_V ):\n",
        "        super(MHA_layer, self).__init__()\n",
        "        self.N_heads = N_heads\n",
        "        self.input_dim = input_dim\n",
        "        self.D_Q = D_Q\n",
        "        self.D_V = D_V\n",
        "        self.WQ = nn.Linear(input_dim, D_Q * N_heads)\n",
        "        self.WK = nn.Linear(input_dim, D_Q * N_heads)\n",
        "        self.WV = nn.Linear(input_dim, D_V * N_heads)\n",
        "        self.OUT = nn.Linear(D_V * N_heads , input_dim)\n",
        "\n",
        "    def forward(self ,x):\n",
        "        size = x.size() # batch x N x input_dim\n",
        "        query = self.WQ(x).view(size[0], size[1] , self.N_heads,  self.D_Q ).transpose(1, 2) # batch x n_heads x N x D_Q\n",
        "        key   = self.WK(x).view(size[0] , size[1] , self.N_heads , self.D_Q).transpose(1, 2) # batch x n_heads x N x D_K\n",
        "        value = self.WV(x).view(size[0] , size[1] , self.N_heads , self.D_V).transpose(1, 2) # batch x n_heads x N x D_K\n",
        "\n",
        "        # Attention calculation same as normal self attention by small varaition because of multiple heads\n",
        "        dot_products = torch.matmul(query , key.transpose(-2,-1))/ torch.sqrt(torch.tensor(self.D_Q, dtype=torch.float32))\n",
        "\n",
        "        softmax = F.softmax(dot_products,dim=-1)\n",
        "\n",
        "        self_attention = torch.matmul(softmax,value)\n",
        "           \n",
        "        self_attention_concatnated = self_attention.transpose(1,2)\n",
        "\n",
        "        # transpose operation may have introduced non-contigous memory \n",
        "        self_attention_concatnated = self_attention_concatnated.contiguous()\n",
        "\n",
        "        #concatnate the values from the heads\n",
        "        self_attention_concatnated = self_attention_concatnated.view(size[0],size[1],-1)\n",
        "\n",
        "        output = self.OUT(self_attention_concatnated)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Encoder Block**\n",
        "A single encoder block consists of the following layers\n",
        "*  Multi-Head Attention Layer\n",
        "*  Residual Connection\n",
        "*  Normalization Layer\n",
        "*  MLP\n",
        "*  Residual Connection\n",
        "*  Normalization Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder_Block(nn.Module):\n",
        "    def __init__(self, input_dim ,inter_dim, N_heads , D_Q , D_V):\n",
        "        super(Encoder_Block, self).__init__()\n",
        "\n",
        "        #MHA Layer\n",
        "        self.MHA = MHA_layer(input_dim, N_heads, D_Q, D_V)\n",
        "\n",
        "        #Layer Normalization\n",
        "        self.Norm_layer1 = nn.LayerNorm(input_dim)\n",
        "\n",
        "        #Feed Forward \n",
        "        self.FF = nn.Sequential(\n",
        "            nn.Linear(input_dim,inter_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(inter_dim,input_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        #Layer Normalization\n",
        "        self.NormLayer2 = nn.LayerNorm(input_dim)\n",
        "\n",
        "    def forward(self ,x):\n",
        "        #get attention\n",
        "        Attention = self.MHA(x)\n",
        "\n",
        "        #add residual and Normalize\n",
        "        Residual_add = self.Norm_layer1( x+ Attention)\n",
        "\n",
        "        #Process through FF\n",
        "        Intermediate = self.FF(Residual_add)\n",
        "\n",
        "        #add residual and Normalize\n",
        "        return self.NormLayer2(Intermediate + Residual_add)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VIT Architecture\n",
        "(Patching &Embbeding) -> Layer Normalization -> 4x[Encode Block] -> classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Object_reconginition_VIT(nn.Module):\n",
        "    def __init__(self, C_in, patch_size,num_patches,Embed_dim, N_C):\n",
        "        super(Object_reconginition_VIT, self).__init__()\n",
        "\n",
        "        #Patching and Embedding\n",
        "        self.patch_size = patch_size\n",
        "        self.flattened_size = C_in * patch_size * patch_size\n",
        "        self.cls_token = nn.Parameter(torch.rand(self.flattened_size))\n",
        "        self.pos_encode = nn.Parameter(torch.rand(1,num_patches+1,self.flattened_size))\n",
        "        self.Embbedding_layer = nn.Linear(C_in * patch_size * patch_size, Embed_dim)\n",
        "\n",
        "        # Normalize Layer\n",
        "        self.Norm = nn.LayerNorm(Embed_dim)\n",
        "\n",
        "        # 4 Encoder Blocks\n",
        "        self.List = nn.ModuleList([\n",
        "            Encoder_Block(input_dim= Embed_dim, inter_dim= (Embed_dim * 2), N_heads=4, D_Q=16, D_V=16)\n",
        "            for _ in range(4)\n",
        "        ])\n",
        "\n",
        "        #Final classfier for the class token \n",
        "        self.classfier = nn.Sequential(\n",
        "            nn.LayerNorm(Embed_dim),\n",
        "            nn.Linear(Embed_dim , N_C),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    \n",
        "    #Reshape into Patches\n",
        "    def patching(self, x):\n",
        "        B, C, H, W = x.size()\n",
        "        x = nn.Unfold(kernel_size=self.patch_size, stride=self.patch_size,padding=0)(x)\n",
        "        x = x.view(B, C, self.patch_size, self.patch_size, -1).permute(0, 4, 1, 2, 3)\n",
        "        return x\n",
        "   \n",
        "    #Add Position encoding and put class token at first of the image\n",
        "    def prepare(self , x):\n",
        "        batch_size = x.size()[0]\n",
        "        x = self.patching(x)\n",
        "        x = x.flatten(2)\n",
        "        cls_add_batch_wise = self.cls_token.repeat(batch_size, 1, 1)\n",
        "        x = torch.cat((cls_add_batch_wise, x), dim=1)\n",
        "        x = x + self.pos_encode\n",
        "        x = self.Embbedding_layer(x)\n",
        "        return x\n",
        "    \n",
        "    #Forward function \n",
        "    def forward(self, x):\n",
        "        x = self.prepare(x)\n",
        "        x = self.Norm(x)\n",
        "        for module in self.List:\n",
        "            x = module(x)\n",
        "        x = self.classfier(x)\n",
        "\n",
        "        #Return output for class Token\n",
        "        return x[:,0]\n",
        "\n",
        "    def train_model(self, train_loader, learning_rate, epochs, batch_size,  device):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        print(\"Training VIT Transformer:\")\n",
        "        Train_loss_data = [] \n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "                #Save inputs in device\n",
        "                inputs, labels = data[0].to(device), data[1].to(device) \n",
        "\n",
        "                #Clear the gradient\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(inputs)  \n",
        "                loss = criterion(outputs.squeeze(), labels)  \n",
        "\n",
        "                #Go backward\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                running_loss += loss.item()\n",
        "\n",
        "            print('epoch : %d ------> loss: %.3f' %\n",
        "                  (epoch + 1, running_loss / len(train_loader)))\n",
        "            Train_loss_data.append(running_loss / len(train_loader))\n",
        "\n",
        "        return Train_loss_data\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training VIT Transformer:\n",
            "epoch : 1 ------> loss: 1.910\n",
            "epoch : 2 ------> loss: 1.480\n",
            "epoch : 3 ------> loss: 1.304\n",
            "epoch : 4 ------> loss: 1.214\n",
            "epoch : 5 ------> loss: 1.145\n",
            "epoch : 6 ------> loss: 1.094\n",
            "epoch : 7 ------> loss: 1.050\n",
            "epoch : 8 ------> loss: 1.017\n",
            "epoch : 9 ------> loss: 0.977\n",
            "epoch : 10 ------> loss: 0.947\n"
          ]
        }
      ],
      "source": [
        "model2 = Object_reconginition_VIT(C_in=3, patch_size=2 , num_patches=256, Embed_dim=32, N_C=10)\n",
        "model2.to(device)\n",
        "Train_loss_data2 = model2.train_model(train_loader, 0.001, 10, 128 , device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([16])\n",
            "Accuracy on the test dataset: 63.28 %\n"
          ]
        }
      ],
      "source": [
        "AC2 = evaluate(model2,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49290\n",
            "54914\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(count_parameters(model))\n",
        "print(count_parameters(model2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1) Lets first observe the training Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(1, epochs + 1), Train_loss_data1, label='CNN-SA')\n",
        "plt.plot(range(1,epochs + 1 ),Train_loss_data2 ,label='VIT')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* CNN-SA is performs slightly better than VIT at later epochs of the training \n",
        "* Both has comparable No of parameters\n",
        "* The following resaons can give the insights \n",
        "  - CNN-SA captures the spatial/local patterns \n",
        "  - CNN-SA and VIT might need different optimizers\n",
        "  - VIT might need more embbeding dimensions to be on par with CNN-SA\n",
        "  - VIT can improve compared to CNN-SA if given suitable EMBED_DIM\n",
        "  - VIT can perform better on larger datasets where attention is heavily required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2) Lets first observe the Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of CNN-SA :  69.28999999999999\n",
            "Accuracy of VIT :  63.28\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy of CNN-SA : \",AC1)\n",
        "print(\"Accuracy of VIT : \",AC2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Same as Training loss \n",
        "* Both are performing better than Normal FF Networks\n",
        "* Can be improved with enough training cycles"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
